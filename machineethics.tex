\section{Moral Ethics}

With the emergence of automated automobiles, various ethical issues arise. While
the introduction of automated vehicles to the mass market is said to be
inevitable due to a (presumed but untestable) potential for reduction of crashes
by "up to" 90\% \cite{wiki1} and their potential greater accessibility to
disabled, elderly, and young passengers, a range of ethical issues have not been
fully addressed. Those include, but are not limited to: the moral, financial,
and criminal responsibility for crashes and breaches of law; the decisions a car
is to make right before a (fatal) crash; privacy issues including potential for
mass surveillance; potential for massive job losses and unemployment among
drivers; de-skilling and loss of independence by vehicle users; exposure to
hacking and malware; and the further concentration of market and data power in
the hands of a few global conglomerates capable of consolidating AI capacity,
and of lobbying governments to facilitate the shift of liability onto others and
their potential destruction of existing occupations and industries.

There are different opinions on who should be held liable in case of a crash,
especially with people being hurt. Many experts see the car manufacturers
themselves responsible for those crashes that occur due to a technical
malfunction or misconstruction. \cite{wiki2} Besides the fact that the car
manufacturer would be the source of the problem in a situation where a car
crashes due to a technical issue, there is another important reason why car
manufacturers could be held responsible: it would encourage them to innovate and
heavily invest into fixing those issues, not only due to protection of the brand
image, but also due to financial and criminal consequences. However, there are
also voices that argue those using or owning the
vehicle should be held responsible since they know the risks involved in using
such a vehicle. Experts  suggest introducing a tax or
insurances that would protect owners and users of automated vehicles of claims
made by victims of an accident. \cite{wiki2} Other possible parties that can
be held responsible in case of a technical failure include \emph{software
engineers} that programmed the code for the automated operation of the
vehicles, and suppliers of components of the AV. \cite{wiki3}

Taking aside the question of legal liability and moral responsibility, the
question arises how automated vehicles should be programmed to behave in an
emergency situation where either passengers or other traffic participants like:
pedestrians, bicyclists and other drivers are endangered. A moral dilemma that a
software engineer or car manufacturer might face in programming the operating
software is described in an ethical thought experiment, the trolley problem: a
conductor of a trolley has the choice of staying on the planned track and
running over five people, or turn the trolley onto a track where it would kill
only one person, assuming there is no traffic on it. \cite{wiki4} When a
self-driving car is in following scenario: it's driving with passengers and
suddenly a person appears in its way. The car has to decide between the two
options, either to run the person over or to avoid hitting the person by
swerving into a wall, killing the passengers. There are two main considerations that need to be addressed. First, what moral
basis would be used by an automated vehicle to make decisions? Second, how could
those be translated into software code? Researchers have suggested, in
particular, two ethical theories to be applicable to the behavior of automated
vehicles in cases of emergency: Asimov's [[Three Laws of Robotics|three laws of robotics]] are a typical example
of deontological ethics. The theory suggests that an automated car needs to
follow strict written-out rules that it needs to follow in any situation.
Utilitarianism suggests the idea that any decision must be made based on the
goal to maximize utility. This needs a definition of utility which could be
maximizing the number of people surviving in a crash. Critics suggest that
automated vehicles should adapt a mix of multiple theories to be able to respond
morally right in the instance of a crash.\cite{wiki3}

Many 'Trolley' discussions skip over the practical problems of how a
probabilistic machine learning vehicle AI could be sophisticated enough to
understand that a deep problem of moral philosophy is presenting itself from
instant to instant while using a dynamic projection into the near future, what
sort of moral problem it actually would be if any, what the relevant weightings
in human value terms should be given to all the other humans involved who will
be probably unreliably identified, and how reliably it can assess the probable
outcomes. These practical difficulties, and those around testing and assessment
of solutions to them, may present as much of a challenge as the theoretical
abstractions.

Privacy-related issues arise mainly from the interconnectivity of automated
cars, making it just another mobile device that can gather any information about
an individual. This information gathering ranges from tracking of the routes
taken, voice recording, video recording, preferences in media that is consumed
in the car, behavioral patterns, to many more streams of information. The data and
communications infrastructure needed to support these vehicles may also be
capable of surveillance, especially if coupled to other data sets and advanced
analytics.

The implementation of automated vehicles to the mass market might cost up to 5
million jobs in the US alone, making up almost 3\% of the workforce. Those jobs
include drivers of taxis, buses, vans, trucks, and e-hailing vehicles. Many
industries, such as the auto insurance industry are indirectly affected. This
industry alone generates an annual revenue of about \$220 billion, supporting
277,000 jobs. To put this into perspective â€“ this is about the number of
mechanical engineering jobs. The potential loss of a majority of those jobs will
have a tremendous impact on those individuals involved. Both India and China
have placed bans on automated cars with the former citing protection of jobs.
